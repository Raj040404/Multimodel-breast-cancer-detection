{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a7839fe-3b7f-43ac-93d4-cb907cb9cf7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of images numpy array: (9, 128, 128, 3)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# Function to load all images, resize them, and convert to numpy array\n",
    "def load_images_from_directory(directory_path, image_size=(128, 128)):\n",
    "    image_list = []\n",
    "    \n",
    "    # Iterate through all files in the directory\n",
    "    for filename in os.listdir(directory_path):\n",
    "        file_path = os.path.join(directory_path, filename)\n",
    "        \n",
    "        # Only process image files (you can extend this to other formats if needed)\n",
    "        if file_path.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif')):\n",
    "            try:\n",
    "                # Open the image\n",
    "                with Image.open(file_path) as img:\n",
    "                    # Resize the image to the target size (128x128)\n",
    "                    img = img.resize(image_size)\n",
    "                    \n",
    "                    # Convert to RGB (if it's in a different mode like RGBA or grayscale)\n",
    "                    img = img.convert('RGB')\n",
    "                    \n",
    "                    # Convert the image to a numpy array and append to the list\n",
    "                    image_array = np.array(img)\n",
    "                    image_list.append(image_array)\n",
    "            except Exception as e:\n",
    "                print(f\"Could not process image {filename}: {e}\")\n",
    "    \n",
    "    # Convert the list of images into a numpy array (shape will be: (num_images, 128, 128, 3))\n",
    "    images_np = np.array(image_list)\n",
    "    return images_np\n",
    "\n",
    "# Path to your directory containing images\n",
    "directory_path = \"C:\\\\Users\\\\91826\\\\OneDrive - SRM Institute of Science & Technology\\\\Desktop\\\\artender\\\\minor_project\\\\ultrasound\\\\images\"\n",
    "\n",
    "# Load images from the directory as numpy array\n",
    "images = load_images_from_directory(directory_path)\n",
    "\n",
    "# Print the shape of the resulting numpy array\n",
    "print(f\"Shape of images numpy array: {images.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab5d312f-6ab2-4cc3-a409-df567f85e10e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 128, 3)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "images= images/255\n",
    "print(images[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90613f62-2f67-4a2b-98b1-935f2284f7e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 141ms/step\n",
      "Prediction: 0.99999857\n",
      "Prediction: 6\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Load the .h5 model\n",
    "model1 = tf.keras.models.load_model(\"C:\\\\Users\\\\91826\\\\OneDrive - SRM Institute of Science & Technology\\\\Desktop\\\\artender\\\\minor_project\\\\ultrasound\\\\cnn_model1.h5\")\n",
    "\n",
    "prediction = model1.predict([images])  # Use X[0] if you want the first sample's prediction\n",
    "\n",
    "# Output the prediction\n",
    "print(\"Prediction:\",np.max(prediction))\n",
    "print(\"Prediction:\", np.argmax(prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "600725b5-7117-403c-b828-b26be544ae3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 946ms/step\n",
      "Prediction: 0.9626683\n",
      "Prediction: 0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Load the .h5 model\n",
    "model2 = tf.keras.models.load_model(\"C:\\\\Users\\\\91826\\\\OneDrive - SRM Institute of Science & Technology\\\\Desktop\\\\artender\\\\minor_project\\\\ultrasound\\\\imagenet_model2.h5\")\n",
    "\n",
    "prediction = model2.predict([images])  # Use X[0] if you want the first sample's prediction\n",
    "\n",
    "# Output the prediction\n",
    "print(\"Prediction:\", np.max(prediction))\n",
    "print(\"Prediction:\", np.argmax(prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "095b6bf6-c83b-43fa-957e-8863c2240dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "image_list=[]\n",
    "image_size=(128,128)\n",
    "\n",
    "file_path=\"C:\\\\Users\\\\91826\\\\OneDrive - SRM Institute of Science & Technology\\\\Desktop\\\\artender\\\\minor_project\\\\ultrasound\\\\images\\\\WhatsApp Image 2025-03-28 at 17.50.12_fc5057fd.jpg\"\n",
    "\n",
    "with Image.open(file_path) as img:\n",
    "                    # Resize the image to the target size (128x128)\n",
    "    img = img.resize(image_size)\n",
    "                    \n",
    "                    # Convert to RGB (if it's in a different mode like RGBA or grayscale)\n",
    "    img = img.convert('RGB')\n",
    "                    \n",
    "                    # Convert the image to a numpy array and append to the list\n",
    "    image_array = np.array(img)\n",
    "    image_list.append(image_array)\n",
    "image_list=np.array(image_list)\n",
    "image_list=image_list/255\n",
    "\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a635f086-2307-4278-a271-9559a6aa7d5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "C:\\Users\\91826\\OneDrive - SRM Institute of Science & Technology\\Desktop\\artender\\minor_project\\tf_env\\Lib\\site-packages\\keras\\src\\models\\functional.py:238: UserWarning: The structure of `inputs` doesn't match the expected structure.\n",
      "Expected: input_2\n",
      "Received: inputs=('Tensor(shape=(1, 128, 128, 3))',)\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x00000213DE2FD580> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x00000213DE2FD580> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "Prediction: 0.9626683\n",
      "Prediction: 0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Load the .h5 model\n",
    "model2 = tf.keras.models.load_model(\"C:\\\\Users\\\\91826\\\\OneDrive - SRM Institute of Science & Technology\\\\Desktop\\\\artender\\\\minor_project\\\\ultrasound\\\\imagenet_model2.h5\")\n",
    "\n",
    "prediction = model2.predict([image_list])  # Use X[0] if you want the first sample's prediction\n",
    "\n",
    "# Output the prediction\n",
    "print(\"Prediction:\", np.max(prediction))\n",
    "print(\"Prediction:\", np.argmax(prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb76954-e1d4-44a5-8885-82e6bfb67a0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
